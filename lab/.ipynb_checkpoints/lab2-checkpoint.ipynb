{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, glob\n",
    "current_location = os.getcwd()\n",
    "os.chdir(current_location)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "Obtain the attitudes dataset. Here, the first variable, attitude, represents the amount of positive attitude of the students who have taken an examination and the score represents the marks scored by the participants in the examination.\n",
    "\n",
    "Express the relationship between the predictor (attitude) and the outcome (score) variables using a linear equation.\n",
    "\n",
    "Using whatever means necessary (may be first by hand and then using a tool), solve the equation.\n",
    "\n",
    "Find your predictions for score for the following values of attitude: 60, 63, 78, 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Attitude</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #  Attitude  Score\n",
       "0  1        65    129\n",
       "1  2        67    126\n",
       "2  3        68    143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/attitude.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choyademacbook/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Score</td>      <th>  R-squared:         </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   62.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:46:25</td>     <th>  Log-Likelihood:    </th> <td> -34.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   72.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   72.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -330.4606</td> <td>   61.829</td> <td>   -5.345</td> <td> 0.001</td> <td> -473.039</td> <td> -187.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attitude</th>  <td>    6.9329</td> <td>    0.875</td> <td>    7.923</td> <td> 0.000</td> <td>    4.915</td> <td>    8.951</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.783</td> <th>  Durbin-Watson:     </th> <td>   1.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.676</td> <th>  Jarque-Bera (JB):  </th> <td>   0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.044</td> <th>  Prob(JB):          </th> <td>   0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.826</td> <th>  Cond. No.          </th> <td>1.70e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.7e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Score   R-squared:                       0.887\n",
       "Model:                            OLS   Adj. R-squared:                  0.873\n",
       "Method:                 Least Squares   F-statistic:                     62.78\n",
       "Date:                Sat, 20 Feb 2021   Prob (F-statistic):           4.68e-05\n",
       "Time:                        20:46:25   Log-Likelihood:                -34.033\n",
       "No. Observations:                  10   AIC:                             72.07\n",
       "Df Residuals:                       8   BIC:                             72.67\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -330.4606     61.829     -5.345      0.001    -473.039    -187.882\n",
       "Attitude       6.9329      0.875      7.923      0.000       4.915       8.951\n",
       "==============================================================================\n",
       "Omnibus:                        0.783   Durbin-Watson:                   1.797\n",
       "Prob(Omnibus):                  0.676   Jarque-Bera (JB):                0.578\n",
       "Skew:                          -0.044   Prob(JB):                        0.749\n",
       "Kurtosis:                       1.826   Cond. No.                     1.70e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.7e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the linear model and printing it's summary\n",
    "lr_model = smf.ols(formula = 'Score~Attitude', data = df).fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [-330.46064815] \n",
      "coef: [[6.93287037]]\n",
      "prediction - 60: [[85.51157407]]\n",
      "prediction - 63: [[106.31018519]]\n",
      "prediction - 73: [[175.63888889]]\n",
      "prediction - 80: [[224.16898148]]\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "x_train = df[[\"Attitude\"]]\n",
    "y_train = df[[\"Score\"]]\n",
    "# Train the model using the training sets\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "print(\"intercept:\", regr.intercept_, \"\\ncoef:\", regr.coef_)\n",
    "print(\"prediction - 60:\", regr.predict([[60]]))\n",
    "print(\"prediction - 63:\", regr.predict([[63]]))\n",
    "print(\"prediction - 73:\", regr.predict([[73]]))\n",
    "print(\"prediction - 80:\", regr.predict([[80]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "Obtain the Container Crane Controller Data Set (Links to an external site.). A container crane is used to transport containers from one place to another. The difficulty of this task lies in the fact that the bridge crane is connected to the container by cables causing an opening angle when the container is being transported. Interfering with the operation at high speeds due to oscillation that occurs at the end-point could cause accidents.\n",
    "\n",
    "Use regression analysis to predict the power from speed and angle. This essentially means deriving a linear regression equation. Now do the same using gradient descent approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0,5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Speed  Angle Power\n",
       "0      1     -5   0,3\n",
       "1      2      5   0,3\n",
       "2      3     -2   0,5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/Container_Crane_Controller_Data_Set.csv\", sep=\";\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Power = (df.Power.str.replace(\",\", \".\")).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Power</td>      <th>  R-squared:         </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.07325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:52:54</td>     <th>  Log-Likelihood:    </th> <td>  8.7363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    15</td>      <th>  AIC:               </th> <td>  -11.47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    12</td>      <th>  BIC:               </th> <td>  -9.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.4751</td> <td>    0.084</td> <td>    5.662</td> <td> 0.000</td> <td>    0.292</td> <td>    0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>     <td>   -0.0050</td> <td>    0.013</td> <td>   -0.383</td> <td> 0.709</td> <td>   -0.034</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Angle</th>     <td>    0.0003</td> <td>    0.011</td> <td>    0.023</td> <td> 0.982</td> <td>   -0.025</td> <td>    0.025</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.895</td> <th>  Durbin-Watson:     </th> <td>   1.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.639</td> <th>  Jarque-Bera (JB):  </th> <td>   0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.307</td> <th>  Prob(JB):          </th> <td>   0.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.067</td> <th>  Cond. No.          </th> <td>    14.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Power   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                 -0.153\n",
       "Method:                 Least Squares   F-statistic:                   0.07325\n",
       "Date:                Sat, 20 Feb 2021   Prob (F-statistic):              0.930\n",
       "Time:                        20:52:54   Log-Likelihood:                 8.7363\n",
       "No. Observations:                  15   AIC:                            -11.47\n",
       "Df Residuals:                      12   BIC:                            -9.348\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.4751      0.084      5.662      0.000       0.292       0.658\n",
       "Speed         -0.0050      0.013     -0.383      0.709      -0.034       0.024\n",
       "Angle          0.0003      0.011      0.023      0.982      -0.025       0.025\n",
       "==============================================================================\n",
       "Omnibus:                        0.895   Durbin-Watson:                   1.570\n",
       "Prob(Omnibus):                  0.639   Jarque-Bera (JB):                0.780\n",
       "Skew:                           0.307   Prob(JB):                        0.677\n",
       "Kurtosis:                       2.067   Cond. No.                         14.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the linear model and printing it's summary\n",
    "lr_model = smf.ols(formula = 'Power~ Speed + Angle', data = df).fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta shape (3, 1)\n",
      "before X shape (15, 3)\n",
      "X shape (15, 3)\n",
      "Completed in 6640 iterations.\n",
      "[[ 0.44669262]\n",
      " [-0.01493248]\n",
      " [ 0.00090944]]\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Speed\", \"Angle\"]]\n",
    "X = sm.add_constant(X) # Adds constant/intercept term\n",
    "y = df[\"Power\"]\n",
    "\n",
    "\n",
    "def grad_descent(X, y, alpha, epsilon):\n",
    "    # print(X)\n",
    "    iteration = [0]\n",
    "    i = 0\n",
    "    theta = np.ones(shape=(len(df.columns), 1)) # 3 columns\n",
    "    print(\"theta shape\", theta.shape)\n",
    "    print(\"before X shape\", X.shape)\n",
    "    X = X + np.array([1,0,0]) # 2 columns\n",
    "    print(\"X shape\", X.shape)\n",
    "    cost = [np.transpose(X @ theta - y) @ (X @ theta - y)]\n",
    "    delta = 1\n",
    "    while (delta>epsilon):\n",
    "        \n",
    "        theta = theta - alpha*((np.transpose(X)) @ (X @ theta - y))\n",
    "        cost_val = (np.transpose(X @ theta - y)) @ (X @ theta - y)\n",
    "        cost.append(cost_val)\n",
    "        # print(cost_val)\n",
    "        # print(cost[i+1])\n",
    "        delta = abs(cost[i+1]-cost[i])\n",
    "        if ((cost[i+1]-cost[i]) > 0):\n",
    "            print(\"The cost is increasing. Try reducing alpha.\")\n",
    "            break\n",
    "        iteration.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Completed in %d iterations.\" %(i))\n",
    "    return(theta, cost)\n",
    "\n",
    "y = y.to_numpy()\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "theta, cost = grad_descent(X = preprocessing.scale(X), y=y, alpha=0.0001, epsilon = 10**-10)\n",
    "\n",
    "print (theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "A popular restaurant review website has released the attached dataset (ratings.tsvPreview the document). Here, each row represents an average rating of a restaurant in different aspects as provided by the previous customers. The dataset contains records for the restaurants using the following attributes: ambience, food, service, and overall rating. The first three attributes are predictor variables and the remaining one is the outcome. Use a linear regression model to predict how the predictor attributes impact the overall rating of the restaurant.\n",
    "\n",
    "First, express the linear regression in mathematical form.\n",
    "Then, try solving it by hand as we did in the class. Here, you will have four parameters (the constant, and the three attributes/predictors), with one outcome. You don't have to actually solve this with all possible values for these parameters. Rather, show a couple of possible sets of values for the parameters with the outcome value calculated.\n",
    "Finally, use your favorite programming tool to find the linear regression model and report it in appropriate terms (don't just dump the output from R or Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant</th>\n",
       "      <th>food</th>\n",
       "      <th>ambience</th>\n",
       "      <th>service</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   restaurant  food  ambience  service  rating\n",
       "0           1    85        82       89      78\n",
       "1           2    80        90       80      85\n",
       "2           3    83        86       83      85"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/ratings.tsv\", sep = \"\\t\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choyademacbook/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>food</td>       <th>  R-squared:         </th> <td>   0.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td>0.00147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:02:19</td>     <th>  Log-Likelihood:    </th> <td> -38.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    15</td>      <th>  AIC:               </th> <td>   85.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    11</td>      <th>  BIC:               </th> <td>   88.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   26.9913</td> <td>   10.976</td> <td>    2.459</td> <td> 0.032</td> <td>    2.833</td> <td>   51.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ambience</th>  <td>   -0.1102</td> <td>    0.111</td> <td>   -0.991</td> <td> 0.343</td> <td>   -0.355</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>service</th>   <td>    0.1765</td> <td>    0.207</td> <td>    0.852</td> <td> 0.412</td> <td>   -0.279</td> <td>    0.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>    <td>    0.5732</td> <td>    0.203</td> <td>    2.826</td> <td> 0.016</td> <td>    0.127</td> <td>    1.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.860</td> <th>  Durbin-Watson:     </th> <td>   2.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.651</td> <th>  Jarque-Bera (JB):  </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.002</td> <th>  Prob(JB):          </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.221</td> <th>  Cond. No.          </th> <td>1.51e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   food   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.671\n",
       "Method:                 Least Squares   F-statistic:                     10.50\n",
       "Date:                Sat, 20 Feb 2021   Prob (F-statistic):            0.00147\n",
       "Time:                        21:02:19   Log-Likelihood:                -38.833\n",
       "No. Observations:                  15   AIC:                             85.67\n",
       "Df Residuals:                      11   BIC:                             88.50\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     26.9913     10.976      2.459      0.032       2.833      51.150\n",
       "ambience      -0.1102      0.111     -0.991      0.343      -0.355       0.135\n",
       "service        0.1765      0.207      0.852      0.412      -0.279       0.632\n",
       "rating         0.5732      0.203      2.826      0.016       0.127       1.020\n",
       "==============================================================================\n",
       "Omnibus:                        0.860   Durbin-Watson:                   2.296\n",
       "Prob(Omnibus):                  0.651   Jarque-Bera (JB):                0.030\n",
       "Skew:                           0.002   Prob(JB):                        0.985\n",
       "Kurtosis:                       3.221   Cond. No.                     1.51e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the linear model and printing it's summary\n",
    "lr_model = smf.ols(formula = 'food~ ambience + service + rating', data = df).fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta shape (4, 1)\n",
      "before X shape (15, 4)\n",
      "X shape (15, 4)\n",
      "Completed in 30322 iterations.\n",
      "[[73.13333333]\n",
      " [-1.04156787]\n",
      " [ 1.37631259]\n",
      " [ 4.60694689]]\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"ambience\", \"service\", \"rating\"]]\n",
    "X = sm.add_constant(X) # Adds constant/intercept term\n",
    "y = df[\"food\"]\n",
    "\n",
    "\n",
    "def grad_descent(X, y, alpha, epsilon):\n",
    "    # print(X)\n",
    "    iteration = [0]\n",
    "    i = 0\n",
    "    theta = np.ones(shape=(4, 1)) # 4 columns\n",
    "    print(\"theta shape\", theta.shape)\n",
    "    print(\"before X shape\", X.shape)\n",
    "    X = X + np.array([1,0,0,0]) # 3 columns\n",
    "    print(\"X shape\", X.shape)\n",
    "    cost = [np.transpose(X @ theta - y) @ (X @ theta - y)]\n",
    "    delta = 1\n",
    "    while (delta>epsilon):\n",
    "        \n",
    "        theta = theta - alpha*((np.transpose(X)) @ (X @ theta - y))\n",
    "        cost_val = (np.transpose(X @ theta - y)) @ (X @ theta - y)\n",
    "        cost.append(cost_val)\n",
    "        # print(cost_val)\n",
    "        # print(cost[i+1])\n",
    "        delta = abs(cost[i+1]-cost[i])\n",
    "        if ((cost[i+1]-cost[i]) > 0):\n",
    "            print(\"The cost is increasing. Try reducing alpha.\")\n",
    "            break\n",
    "        iteration.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Completed in %d iterations.\" %(i))\n",
    "    return(theta, cost)\n",
    "\n",
    "y = y.to_numpy()\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "theta, cost = grad_descent(X = preprocessing.scale(X), y=y, alpha=0.0001, epsilon = 10**-10)\n",
    "\n",
    "print (theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "For this problem, we are going to use the All Greens Franchise data set (Links to an external site.). It contain 27 observations about All Greens sales that has five predictor variables apart from the annual net sales figure. Use this dataset and perform the following sets of analyses.\n",
    "\n",
    "Find the correlation of annual net sales with money spent on advertising and number of competitors in the area. Provide your one-sentence interpretation.\n",
    "Build a regression model to predict the annual net sales figure using the other five columns in the data set. Report your model (line equation).\n",
    "Now use gradient descent to learn the regression model. Report your model (gradients) along with the learning rate(s) you used and the cost(s).\n",
    "\n",
    "- X1 = annual net sales/$1000 \n",
    "\n",
    "- X2 = number sq. ft./1000\n",
    "- X3 = inventory/$1000\n",
    "\n",
    "- X4 = amount spent on advertizing/$1000\n",
    "- X5 = size of sales district/1000 families\n",
    "- X6 = number of competing stores in district\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>294</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>232</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>149</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1   X2   X3   X4   X5  X6\n",
       "0  231.0  3.0  294  8.2  8.2  11\n",
       "1  156.0  2.2  232  6.9  4.1  12\n",
       "2   10.0  0.5  149  3.0  4.3  15"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"./data/mlr05.xls\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = df[[\"X1\", \"X4\", \"X6\"]].corr()\n",
    "plot1 = sns.heatmap(corr_matrix, annot=True)\n",
    "plot1.set_title(\"heatmap of the correlation matrix\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>X1</td>        <th>  R-squared:         </th> <td>   0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   611.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>5.40e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:10:54</td>     <th>  Log-Likelihood:    </th> <td> -112.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    27</td>      <th>  AIC:               </th> <td>   236.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   244.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -18.8594</td> <td>   30.150</td> <td>   -0.626</td> <td> 0.538</td> <td>  -81.560</td> <td>   43.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>   16.2016</td> <td>    3.544</td> <td>    4.571</td> <td> 0.000</td> <td>    8.831</td> <td>   23.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    0.1746</td> <td>    0.058</td> <td>    3.032</td> <td> 0.006</td> <td>    0.055</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>   11.5263</td> <td>    2.532</td> <td>    4.552</td> <td> 0.000</td> <td>    6.260</td> <td>   16.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>   13.5803</td> <td>    1.770</td> <td>    7.671</td> <td> 0.000</td> <td>    9.898</td> <td>   17.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>        <td>   -5.3110</td> <td>    1.705</td> <td>   -3.114</td> <td> 0.005</td> <td>   -8.858</td> <td>   -1.764</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.650</td> <th>  Durbin-Watson:     </th> <td>   1.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.059</td> <th>  Jarque-Bera (JB):  </th> <td>   4.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.916</td> <th>  Prob(JB):          </th> <td>   0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.484</td> <th>  Cond. No.          </th> <td>3.84e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.84e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     X1   R-squared:                       0.993\n",
       "Model:                            OLS   Adj. R-squared:                  0.992\n",
       "Method:                 Least Squares   F-statistic:                     611.6\n",
       "Date:                Sat, 20 Feb 2021   Prob (F-statistic):           5.40e-22\n",
       "Time:                        21:10:54   Log-Likelihood:                -112.43\n",
       "No. Observations:                  27   AIC:                             236.9\n",
       "Df Residuals:                      21   BIC:                             244.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -18.8594     30.150     -0.626      0.538     -81.560      43.841\n",
       "X2            16.2016      3.544      4.571      0.000       8.831      23.573\n",
       "X3             0.1746      0.058      3.032      0.006       0.055       0.294\n",
       "X4            11.5263      2.532      4.552      0.000       6.260      16.792\n",
       "X5            13.5803      1.770      7.671      0.000       9.898      17.262\n",
       "X6            -5.3110      1.705     -3.114      0.005      -8.858      -1.764\n",
       "==============================================================================\n",
       "Omnibus:                        5.650   Durbin-Watson:                   1.789\n",
       "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                4.041\n",
       "Skew:                           0.916   Prob(JB):                        0.133\n",
       "Kurtosis:                       3.484   Cond. No.                     3.84e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.84e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the linear model and printing it's summary\n",
    "lr_model = smf.ols(formula = 'X1~ X2+X3+X4+X5+X6', data = df).fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta shape (6, 1)\n",
      "before X shape (27, 6)\n",
      "X shape (27, 6)\n",
      "Completed in 72414 iterations.\n",
      "[[286.57407407]\n",
      " [ 31.97296249]\n",
      " [ 32.76088249]\n",
      " [ 42.69246378]\n",
      " [ 68.49823205]\n",
      " [-25.5154767 ]]\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]]\n",
    "X = sm.add_constant(X) # Adds constant/intercept term\n",
    "y = df[\"X1\"]\n",
    "\n",
    "\n",
    "def grad_descent(X, y, alpha, epsilon):\n",
    "    # print(X)\n",
    "    iteration = [0]\n",
    "    i = 0\n",
    "    theta = np.ones(shape=(6, 1)) # 6 columns\n",
    "    print(\"theta shape\", theta.shape)\n",
    "    print(\"before X shape\", X.shape)\n",
    "    X = X + np.array([1,0,0,0,0,0]) # 5 columns\n",
    "    print(\"X shape\", X.shape)\n",
    "    cost = [np.transpose(X @ theta - y) @ (X @ theta - y)]\n",
    "    delta = 1\n",
    "    while (delta>epsilon):\n",
    "        \n",
    "        theta = theta - alpha*((np.transpose(X)) @ (X @ theta - y))\n",
    "        cost_val = (np.transpose(X @ theta - y)) @ (X @ theta - y)\n",
    "        cost.append(cost_val)\n",
    "        # print(cost_val)\n",
    "        # print(cost[i+1])\n",
    "        delta = abs(cost[i+1]-cost[i])\n",
    "        if ((cost[i+1]-cost[i]) > 0):\n",
    "            print(\"The cost is increasing. Try reducing alpha.\")\n",
    "            break\n",
    "        iteration.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Completed in %d iterations.\" %(i))\n",
    "    return(theta, cost)\n",
    "\n",
    "y = y.to_numpy()\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "theta, cost = grad_descent(X = preprocessing.scale(X), y=y, alpha=0.0001, epsilon = 10**-10)\n",
    "\n",
    "print (theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
